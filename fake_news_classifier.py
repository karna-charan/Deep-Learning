# -*- coding: utf-8 -*-
"""fake news classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lTXoyKGH9qvDhJI1Zo18viBwBAHva7X5
"""

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_name = "mrm8488/bert-tiny-finetuned-fake-news-detection"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

text = input("Enter news text: ")

inputs = tokenizer(text, return_tensors="pt", truncation=True)

with torch.no_grad():
    outputs = model(**inputs)

scores = torch.softmax(outputs.logits, dim=1)

label = torch.argmax(scores).item()
confidence = scores[0][label].item()

print("\n--- Fake News Classification Result ---")
if label == 1:
    print("News Type : REAL")
else:
    print("News Type : FAKE")

print("Confidence :", round(confidence, 3))

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_name = "mrm8488/bert-tiny-finetuned-fake-news-detection"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

text = input("Enter news text: ")

inputs = tokenizer(text, return_tensors="pt", truncation=True)

with torch.no_grad():
    outputs = model(**inputs)

scores = torch.softmax(outputs.logits, dim=1)

label = torch.argmax(scores).item()
confidence = scores[0][label].item()

print("\n--- Fake News Classification Result ---")
if label == 1:
    print("News Type : REAL")
else:
    print("News Type : FAKE")

print("Confidence :", round(confidence, 3))

