# -*- coding: utf-8 -*-
"""hugging face transformation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c86vwS-OfPaZu5jQyRtLQkkob_wcWSVk
"""

import huggingface_hub
from huggingface_hub import hf_hub_download
from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer('all-MiniLM-L6-v2')

sentence1 = input("Enter first sentence: ")
sentence2 = input("Enter second sentence: ")

emb1 = model.encode(sentence1, convert_to_tensor=True)
emb2 = model.encode(sentence2, convert_to_tensor=True)

similarity = util.cos_sim(emb1, emb2)

print("\nSimilarity Score:", round(similarity.item(), 3))

import huggingface_hub
from huggingface_hub import hf_hub_download
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_name = "distilbert-base-uncased-finetuned-sst-2-english"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

text = input("Enter a sentence for sentiment analysis: ")

inputs = tokenizer(text, return_tensors="pt")

outputs = model(**inputs)
scores = torch.softmax(outputs.logits, dim=1)

label = torch.argmax(scores).item()
confidence = scores[0][label].item()

if label == 1:
    print("\nSentiment: POSITIVE")
else:
    print("\nSentiment: NEGATIVE")

print("Confidence Score:", round(confidence, 3))

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_name = "mrm8488/bert-tiny-finetuned-fake-news-detection"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

text = input("Enter news text: ")

inputs = tokenizer(text, return_tensors="pt", truncation=True)

with torch.no_grad():
    outputs = model(**inputs)

scores = torch.softmax(outputs.logits, dim=1)

label = torch.argmax(scores).item()
confidence = scores[0][label].item()

print("\n--- Fake News Classification Result ---")
if label == 1:
    print("News Type : REAL")
else:
    print("News Type : FAKE")

print("Confidence :", round(confidence, 3))

from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_name = "mrm8488/bert-tiny-finetuned-fake-news-detection"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

text = input("Enter news text: ")

inputs = tokenizer(text, return_tensors="pt", truncation=True)

with torch.no_grad():
    outputs = model(**inputs)

scores = torch.softmax(outputs.logits, dim=1)

label = torch.argmax(scores).item()
confidence = scores[0][label].item()

print("\n--- Fake News Classification Result ---")
if label == 1:
    print("News Type : REAL")
else:
    print("News Type : FAKE")

print("Confidence :", round(confidence, 3))

